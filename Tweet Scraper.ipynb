{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication Step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'XXXX\n",
    "consumer_secret = 'XXXX'\n",
    "access_token = 'XXXX'\n",
    "access_token_secret = 'XXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authentication(key, key_secret, token, token_secret):\n",
    "    auth=tweepy.OAuthHandler(key, key_secret)\n",
    "    auth.set_access_token(token,token_secret)\n",
    "    api=tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True,retry_count=5, \n",
    "                   retry_delay=15)\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "        print(\"Authentication was successful\")\n",
    "        return api, auth\n",
    "    except:\n",
    "        print(\"Error during Authenticatin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication was successful\n"
     ]
    }
   ],
   "source": [
    "api, auth = authentication(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Tweets for each terms in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(count,*query):\n",
    "    onelist_df = pd.DataFrame(columns=[\"User_ID\",\"Tweets\", \"User_Name\"])\n",
    "    #print(mega_df)\n",
    "    #print(query)\n",
    "    for i in query:\n",
    "#         for j in i:\n",
    "        print(i)\n",
    "        tweets=tweepy.Cursor(api.search, i).items(count)\n",
    "        tweets_list=[[tt.id, tt.text, tt.user.screen_name] for tt in tweets if tt.lang=='en']\n",
    "        df = pd.DataFrame(data=tweets_list,columns=[\"User_ID\",\"Tweets\", \"User_Name\"])\n",
    "        #print(j,len(df))\n",
    "        onelist_df = onelist_df.append(df)\n",
    "            \n",
    "    return onelist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_christ=[\"fenian\",\"papists\",\"proddy dog\", \"soup takers\",\"spike\"]\n",
    "keywords_judhaism=[\"heebs\",\"holohoax\",\"hooknosed jews\",\"hymie\",\"jewbag\",\"oven dodger\",\"Kike\", \"fuck jews\"]\n",
    "keywords_islam=[\"muslim\",\"islam\",\"islam cult\",\"hijab\",\"islamic terrorists\", \"muzzie\",\"pisslam\",\"raghead\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_black=[\"nigger\",\"nigga\",\"yard ape\",\"black people\",\"negro\",\"fuck blm\",\"coons\",\"ghetto\",\"congoids\",\"dindu nuffin\",\"ghetto monkey\",\"hoodrat\",\"jiggas\",\"coon\",\"kneegrow\",\"niggerettes\",\"picaninnies\",\"spear chucker\"]\n",
    "keywords_asian=[\"rice nigger\",\"chigga\",\"yellow invader\",\"ching chong\", \"chinese virus\",\"sideway vagina\",\"slant eye\"]\n",
    "keywords_brown=[\"sand ape\",\"paki\",\"islamic terror\",\"sand monkey\"]\n",
    "keywords_hispanic=[\"beaner\",\"spic\",\"anchor baby\",\"wetback\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_religon_keywords=[keywords_christ,keywords_judhaism,keywords_islam]\n",
    "all_race_keywords=[keywords_black, keywords_asian,keywords_brown, keywords_hispanic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the function and join all three lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allterms_tweets(count,filename,*args):\n",
    "    final_df = pd.DataFrame(columns=[\"User_ID\",\"Tweets\", \"User_Name\"])\n",
    "    for arg in args:\n",
    "        #print(arg)\n",
    "        onelist_df = scrape_tweets(count,*arg)\n",
    "        #print(onelist_df.columns)\n",
    "        final_df = final_df.append(onelist_df)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rice nigger\n",
      "chigga\n",
      "yellow invader\n",
      "ching chong\n",
      "chinese virus\n",
      "sideway vagina\n",
      "slant eye\n",
      "sand ape\n",
      "paki\n",
      "islamic terror\n",
      "sand monkey\n",
      "beaner\n",
      "spic\n",
      "anchor baby\n",
      "wetback\n"
     ]
    }
   ],
   "source": [
    "race=allterms_tweets(100, *all_race_keywords)\n",
    "race.to_csv(\"extraRace.csv\",encoding=\"utf-8\",mode= 'a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heebs\n",
      "holohoax\n",
      "hooknosed jews\n",
      "hymie\n",
      "jewbag\n",
      "oven dodger\n",
      "Kike\n",
      "fuck jews\n",
      "muslim\n",
      "islam\n",
      "islam cult\n",
      "hijab\n",
      "islamic terrorists\n",
      "muzzie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pisslam\n",
      "raghead\n"
     ]
    }
   ],
   "source": [
    "religon=allterms_tweets(100, *all_religon_keywords)\n",
    "religon.to_csv(\"extrareligion.csv\",encoding=\"utf-8\",mode = 'a',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Tweets in CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(religon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_qt=[\"tranny\",\"hermaphrodite\",\"shemale\",\"trannie\",\"thot\"]\n",
    "keyword_lgb=[\"batty boy\",\"bull dyke\", \"Puto\",\"butt pirate\",\"dyke\",\"sodomite\",\"faggot\",\"homo\",\"fagbag\",\"fruities\",\"fudgepacker\",\"gay mafia\",\"gaylords\",\"gheys\",\"lipstick lesbian\",\"niggerfag\"]\n",
    "keyword_lgbtq=[keyword_qt, keyword_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batty boy\n",
      "bull dyke\n",
      "butt pirate\n",
      "dyke\n",
      "sodomite\n",
      "faggot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\n",
      "fagbag\n",
      "fruities\n",
      "fudgepacker\n",
      "gay mafia\n",
      "gaylords\n",
      "gheys\n",
      "lipstick lesbian\n",
      "niggerfag\n"
     ]
    }
   ],
   "source": [
    "sex_orient=allterms_tweets(100, *keyword_lgbtq)\n",
    "sex_orient.to_csv(\"Anti_LGBTQ.csv\",encoding=\"utf-8\",mode = 'a',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sex_orient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
